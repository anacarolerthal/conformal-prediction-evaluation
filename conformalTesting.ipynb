{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# The batch size\n",
    "batch_size = 512 \n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "trains_set, validation_set = random_split(train_set, [0.75, 0.25])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_set, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, conv1_hidden=6, conv2_hidden=16, conv_kernel_size=5, pool_kernel_size=2, pool_stride=2, linear1_hidden=120, linear2_hidden=84):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, conv1_hidden, conv_kernel_size)\n",
    "        self.pool = nn.MaxPool2d(pool_kernel_size, pool_stride)\n",
    "        self.conv2 = nn.Conv2d(conv1_hidden, conv2_hidden, conv_kernel_size)\n",
    "        self.fc1 = nn.Linear(conv2_hidden * 5 * 5, linear1_hidden)\n",
    "        self.fc2 = nn.Linear(linear1_hidden, linear2_hidden)\n",
    "        self.fc3 = nn.Linear(linear2_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        intermediate_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        intermediate_outputs.append(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        intermediate_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        intermediate_outputs.append(x)\n",
    "        x = self.pool(F.relu(x))\n",
    "        intermediate_outputs.append(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        intermediate_outputs.append(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        intermediate_outputs.append(x)\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        intermediate_outputs.append(x)\n",
    "\n",
    "        return x, intermediate_outputs\n",
    "    \n",
    "cnn = CNN().to(device)\n",
    "optimizer_cnn = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer_cnn.zero_grad()\n",
    "        outputs, intermediate_outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cnn.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs, intermediate_outputs = cnn(inputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.detach().numpy()\n",
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"labels.csv\", \"w\")\n",
    "f.write(\"label;output\\n\")\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    labels_str = labels[i]\n",
    "    outputs_str = str(outputs[i])\n",
    "    # remove \\n from string\n",
    "    outputs_str = outputs_str.replace(\"\\n\", \"\")\n",
    "    f.write(str(labels_str) +\";\"+ str(outputs_str) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1.9216972e-07, 0.002469865, 3.1885104e-12, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.20628296, 1.48559475e-05, 1.4134733e-06, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>[4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>[8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7</td>\n",
       "      <td>[4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             output\n",
       "0         3  [2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...\n",
       "1         8  [2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...\n",
       "2         8  [1.9216972e-07, 0.002469865, 3.1885104e-12, 3....\n",
       "3         0  [0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...\n",
       "4         6  [3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...\n",
       "...     ...                                                ...\n",
       "9995      8  [0.20628296, 1.48559475e-05, 1.4134733e-06, 2....\n",
       "9996      3  [4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...\n",
       "9997      5  [8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...\n",
       "9998      1  [1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...\n",
       "9999      7  [4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make df where column \"label\" is column 10 of data_cifar10_probs and column \"output\" is an array of the first 10 columns of data_cifar10_probs as a list of floats\n",
    "data_cifar10_probs = pd.read_csv('notebooks/cifar10_probs.csv', sep=',', header=None)\n",
    "data_cifar10_probs = data_cifar10_probs.rename(columns={10: \"label\"})\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs.iloc[:, 0:10].values.tolist()\n",
    "# make \n",
    "\n",
    "data_cifar10_probs = data_cifar10_probs.drop(data_cifar10_probs.columns[0:10], axis=1)\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs[\"output\"].astype(str)\n",
    "\n",
    "data_cifar10_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to remember to turn \" \" into \",\"\n",
    "data1 = pd.read_csv('labels (2).csv', sep=';')\n",
    "# get types of columns\n",
    "type(data1[\"output\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to remember to turn \" \" into \",\"\n",
    "\n",
    "smx = data_cifar10_probs['output']\n",
    "labels = data_cifar10_probs['label'].astype(int)\n",
    "\n",
    "# create an empty array\n",
    "lista = np.array([])\n",
    "for i in range(len(smx)):\n",
    "    lista = np.append(lista, literal_eval(smx[i]))\n",
    "    \n",
    "smx = lista.reshape(len(smx), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=300 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "#val_smx = val_smx[2].reshape(1,10) #use to have 1 img to predict\n",
    "\n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])\n",
    "#cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])[2] #use to have 1 img to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 10), (9700, 10))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_smx.shape, val_smx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (9700,))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_labels.shape, val_labels.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal prediction happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "\n",
    "# criamos um vetor cal_scores com (1 -(probabilidade atribuida pelo modelo de que a imagem tenha seu label verdadeiro))\n",
    "# cal score Ã© quanto menor, melhor\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "\n",
    "# 2: get adjusted quantile\n",
    "# qhat serÃ¡ o valor de s_i (entrada de cal_scores) que limita os 1-alpha menores scores (os melhores!)\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9661855670103093\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9700, 10)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9700,)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "873\n"
     ]
    }
   ],
   "source": [
    "# prediction_sets_one_guess = prediction_set removing all lists with only one guess\n",
    "prediction_sets_many_guesses = []\n",
    "for i in range(len(prediction_sets)):\n",
    "    if prediction_sets[i].sum() != 1:\n",
    "        prediction_sets_many_guesses.append(prediction_sets[i])\n",
    "    else:\n",
    "        # make val_labels[i]==-1\n",
    "        val_labels[i] = -1\n",
    "\n",
    "# remove all -1 from val_labels\n",
    "val_labels = val_labels[val_labels != -1]\n",
    "\n",
    "# get the accuracy of the model\n",
    "accuracy = 0\n",
    "for i in range(len(prediction_sets_many_guesses)):\n",
    "    if prediction_sets_many_guesses[i][val_labels[i]] == True:\n",
    "        accuracy += 1\n",
    "print(accuracy)\n",
    "print(len(prediction_sets_many_guesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8591\n",
      "8855\n"
     ]
    }
   ],
   "source": [
    "# prediction_sets_one_guess = prediction_set removing all lists with more than one guess\n",
    "prediction_sets_one_guess = []\n",
    "for i in range(len(prediction_sets)):\n",
    "    if prediction_sets[i].sum() == 1:\n",
    "        prediction_sets_one_guess.append(prediction_sets[i])\n",
    "    else:\n",
    "        # make val_labels[i]==-1\n",
    "        val_labels[i] = -1\n",
    "\n",
    "# remove all -1 from val_labels\n",
    "val_labels = val_labels[val_labels != -1]\n",
    "\n",
    "# get the accuracy of the model\n",
    "accuracy = 0\n",
    "for i in range(len(prediction_sets_one_guess)):\n",
    "    if prediction_sets_one_guess[i][val_labels[i]] == True:\n",
    "        accuracy += 1\n",
    "print(accuracy)\n",
    "print(len(prediction_sets_one_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times there is more than one label in the prediction set is: 0\n"
     ]
    }
   ],
   "source": [
    "# count how many times there is more than one label in the prediction set\n",
    "count = 0\n",
    "for i in range(len(prediction_sets)):\n",
    "    if sum(prediction_sets[i]) > 9:\n",
    "        count += 1\n",
    "print(f\"The number of times there is more than one label in the prediction set is: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
