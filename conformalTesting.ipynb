{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para utilizar o `cifar10_probs.csv`, que contém logits da ResNet110 no conjunto de teste do CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1.9216972e-07, 0.002469865, 3.1885104e-12, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.20628296, 1.48559475e-05, 1.4134733e-06, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>[4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>[8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7</td>\n",
       "      <td>[4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             output\n",
       "0         3  [2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...\n",
       "1         8  [2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...\n",
       "2         8  [1.9216972e-07, 0.002469865, 3.1885104e-12, 3....\n",
       "3         0  [0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...\n",
       "4         6  [3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...\n",
       "...     ...                                                ...\n",
       "9995      8  [0.20628296, 1.48559475e-05, 1.4134733e-06, 2....\n",
       "9996      3  [4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...\n",
       "9997      5  [8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...\n",
       "9998      1  [1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...\n",
       "9999      7  [4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell to run on cifar10_probs.csv (from resnet110)\n",
    "\n",
    "# make df where column \"label\" is column 10 of data_cifar10_probs and column \"output\" is an array of the first 10 columns of data_cifar10_probs as a list of floats\n",
    "data_cifar10_probs = pd.read_csv('notebooks/cifar10_probs.csv', sep=',', header=None)\n",
    "data_cifar10_probs = data_cifar10_probs.rename(columns={10: \"label\"})\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs.iloc[:, 0:10].values.tolist()\n",
    "\n",
    "# organize df as conformal requires\n",
    "data_cifar10_probs = data_cifar10_probs.drop(data_cifar10_probs.columns[0:10], axis=1)\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs[\"output\"].astype(str)\n",
    "\n",
    "data_cifar10_probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para utilizar o `labels_convolutional_cifar10.csv`, que contém logits de uma rede convolucional própria no conjunto de teste do CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to run on labels_convolutional_cifar10.csv\n",
    "\n",
    "# # we have to remember to turn \" \" into \",\"\n",
    "# data1 = pd.read_csv('labels (2).csv', sep=';')\n",
    "# # get types of columns\n",
    "# type(data1[\"output\"][0])\n",
    "\n",
    "# we have to remember to turn \" \" into \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "smx = data_cifar10_probs['output'] # softmax probabilities\n",
    "labels = data_cifar10_probs['label'].astype(int) # true labels\n",
    "\n",
    "# create an empty array\n",
    "lista = np.array([])\n",
    "for i in range(len(smx)):\n",
    "    lista = np.append(lista, literal_eval(smx[i]))\n",
    "\n",
    "smx = lista.reshape(len(smx), 10)\n",
    "# print(smx.shape) # (10000, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical conformal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10) (9500, 10)\n",
      "(500,) (9500,)\n"
     ]
    }
   ],
   "source": [
    "print(cal_smx.shape, val_smx.shape)\n",
    "print(cal_labels.shape, val_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the actual conformal prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "\n",
    "# criamos um vetor cal_scores com (1 -(probabilidade atribuida pelo modelo de que a imagem tenha seu label verdadeiro))\n",
    "# cal score é quanto menor, melhor\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "\n",
    "# 2: get adjusted quantile\n",
    "# qhat será o valor de s_i (entrada de cal_scores) que limita os 1-alpha menores scores (os melhores!)\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.991578947368421\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do conformal prediction but we only want one label in the prediction set, so we look for the alpha when the set goes from 2 to 1 label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_scores = 1 - cal_smx[np.arange(n), cal_labels]\n",
    "alphas = []\n",
    "prediction_sets = []\n",
    "actual_labels = []\n",
    "i =0 \n",
    "for i, image in enumerate(val_smx):\n",
    "    # try alphas until there's only one class in the prediction set\n",
    "    for alpha in np.arange(0.01, 1, 0.0001):\n",
    "        q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
    "        qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "        prediction_set = image >= (1 - qhat)  # 3: form prediction sets\n",
    "\n",
    "        if np.sum(prediction_set) == 1:\n",
    "            prediction_sets.append(prediction_set)\n",
    "            alphas.append(alpha)\n",
    "            # put val_labels[i] in actual_labels\n",
    "            actual_labels.append(val_labels[i])\n",
    "            break  # exit the inner loop if an alpha is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9485, 10)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to array prediction_sets\n",
    "prediction_sets = np.array(prediction_sets)\n",
    "# to array actual_labels\n",
    "actual_labels = np.array(actual_labels)\n",
    "prediction_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9375856615709014\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),actual_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.986, 0.99 , 0.97 , ..., 0.99 , 0.97 , 0.99 ])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create fake logits list (1-alphas)\n",
    "fake_logits = 1 - np.array(alphas)\n",
    "fake_logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "val_smx = val_smx[2].reshape(1,10) #use to have 1 img to predict\n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])[2] #use to have 1 img to predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
