{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "path = sys.path.insert(1,\"C:/PythonEnviroments/pytorch_resnet_cifar10\")\n",
    "from resnet import resnet110\n",
    "import dill  # in order to save Lambda Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network architecture coresponding to the checkpoint\n",
    "model = resnet110()\n",
    "\n",
    "# remember to set map_location\n",
    "check_point = torch.load('models/resnet110-1d1ed7c2.pth', map_location='cuda:0')\n",
    "\n",
    "# cause the model are saved from Parallel, we need to wrap it\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(check_point['state_dict'])\n",
    "\n",
    "# pay attention to .module! without this, if you load the model, it will be attached with [Parallel.module]\n",
    "# that will lead to some trouble!\n",
    "torch.save(model.module, 'resnet20_check_point.pth', pickle_module=dill)\n",
    "\n",
    "# load the converted pretrained model\n",
    "net = torch.load('resnet20_check_point.pth', map_location='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=128, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
