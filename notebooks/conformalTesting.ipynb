{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para utilizar o `cifar10_probs.csv`, que contém logits da ResNet110 no conjunto de teste do CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1.9216972e-07, 0.002469865, 3.1885104e-12, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.20628296, 1.48559475e-05, 1.4134733e-06, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>[4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>[8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7</td>\n",
       "      <td>[4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             output\n",
       "0         3  [2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...\n",
       "1         8  [2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...\n",
       "2         8  [1.9216972e-07, 0.002469865, 3.1885104e-12, 3....\n",
       "3         0  [0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...\n",
       "4         6  [3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...\n",
       "...     ...                                                ...\n",
       "9995      8  [0.20628296, 1.48559475e-05, 1.4134733e-06, 2....\n",
       "9996      3  [4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...\n",
       "9997      5  [8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...\n",
       "9998      1  [1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...\n",
       "9999      7  [4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell to run on cifar10_probs.csv (from resnet110)\n",
    "\n",
    "# make df where column \"label\" is column 10 of data_cifar10_probs and column \"output\" is an array of the first 10 columns of data_cifar10_probs as a list of floats\n",
    "data_cifar10_probs = pd.read_csv('../data-files/cifar10_probs.csv', sep=',', header=None)\n",
    "data_cifar10_probs = data_cifar10_probs.rename(columns={10: \"label\"})\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs.iloc[:, 0:10].values.tolist()\n",
    "\n",
    "# organize df as conformal requires\n",
    "data_cifar10_probs = data_cifar10_probs.drop(data_cifar10_probs.columns[0:10], axis=1)\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs[\"output\"].astype(str)\n",
    "\n",
    "data_cifar10_probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para utilizar o `labels_convolutional_cifar10.csv`, que contém logits de uma rede convolucional própria no conjunto de teste do CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to run on labels_convolutional_cifar10.csv\n",
    "\n",
    "# # we have to remember to turn \" \" into \",\"\n",
    "# data1 = pd.read_csv('labels (2).csv', sep=';')\n",
    "# # get types of columns\n",
    "# type(data1[\"output\"][0])\n",
    "\n",
    "# we have to remember to turn \" \" into \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "smx = data_cifar10_probs['output'] # softmax probabilities\n",
    "labels = data_cifar10_probs['label'].astype(int) # true labels\n",
    "\n",
    "# create an empty array\n",
    "lista = np.array([])\n",
    "for i in range(len(smx)):\n",
    "    lista = np.append(lista, literal_eval(smx[i]))\n",
    "\n",
    "smx = lista.reshape(len(smx), 10)\n",
    "# print(smx.shape) # (10000, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical conformal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10) (9500, 10)\n",
      "(500,) (9500,)\n"
     ]
    }
   ],
   "source": [
    "print(cal_smx.shape, val_smx.shape)\n",
    "print(cal_labels.shape, val_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the actual conformal prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "\n",
    "# criamos um vetor cal_scores com (1 -(probabilidade atribuida pelo modelo de que a imagem tenha seu label verdadeiro))\n",
    "# cal score é quanto menor, melhor\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "\n",
    "# 2: get adjusted quantile\n",
    "# qhat será o valor de s_i (entrada de cal_scores) que limita os 1-alpha menores scores (os melhores!)\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9868421052631579\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do conformal prediction but we only want one label in the prediction set, so we look for the alpha when the set goes from 2 to 1 label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_scores = 1 - cal_smx[np.arange(n), cal_labels]\n",
    "alphas = []\n",
    "prediction_sets = []\n",
    "actual_labels = []\n",
    "i =0 \n",
    "for i, image in enumerate(val_smx):\n",
    "    # try alphas until there's only one class in the prediction set\n",
    "    for alpha in np.arange(0.01, 1, 0.0001):\n",
    "        q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
    "        qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "        prediction_set = image >= (1 - qhat)  # 3: form prediction sets\n",
    "\n",
    "        if np.sum(prediction_set) == 1:\n",
    "            prediction_sets.append(prediction_set)\n",
    "            alphas.append(alpha)\n",
    "            # put val_labels[i] in actual_labels\n",
    "            actual_labels.append(val_labels[i])\n",
    "            break  # exit the inner loop if an alpha is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to array prediction_sets\n",
    "prediction_sets = np.array(prediction_sets)\n",
    "# to array actual_labels\n",
    "actual_labels = np.array(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9368732186213449\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),actual_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99 , 0.99 , 0.982, ..., 0.99 , 0.988, 0.99 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create fake logits list (1-alphas)\n",
    "fake_logits = 1 - np.array(alphas)\n",
    "fake_logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "val_smx = val_smx[2].reshape(1,10) #use to have 1 img to predict\n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])[2] #use to have 1 img to predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "Here we assume CIFAR10 dataset, but it can be any dataset, just remember to set n_classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receives directory of datafile in csv format and returns a dataframe\n",
    "# datafile must be: prob1, prob2, ..., prob10, label\n",
    "def datafile_to_df(datafile_directory, n_classes=10):\n",
    "    data = pd.read_csv(datafile_directory, sep=',', header=None)\n",
    "    data = data.rename(columns={n_classes: \"label\"})\n",
    "    data[\"output\"] = data.iloc[:, 0:n_classes].values.tolist()\n",
    "    data = data.drop(data.columns[0:n_classes], axis=1)\n",
    "    data[\"output\"] = data[\"output\"].astype(str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receives data from datafile_to_df and returns smx and labels\n",
    "def get_smx_and_labels(data, n_classes=10):\n",
    "    smx = data['output'] \n",
    "    labels = data['label'].astype(int)\n",
    "\n",
    "    lista = np.array([])\n",
    "    for i in range(len(smx)):\n",
    "        lista = np.append(lista, literal_eval(smx[i]))\n",
    "\n",
    "    smx = lista.reshape(len(smx), n_classes)\n",
    "    return smx, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate calibration and validation sets (both smx and labels)\n",
    "def generate_cal_val_sets(smx, labels, size_cal_set):\n",
    "    idx = np.array([1] * size_cal_set + [0] * (smx.shape[0]-size_cal_set)) > 0 \n",
    "    np.random.shuffle(idx) \n",
    "    cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "    cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])\n",
    "    \n",
    "    return cal_smx, val_smx, cal_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do actual conformal prediction\n",
    "def conformal(cal_smx, cal_labels, val_labels, val_smx, size_cal_set):\n",
    "    cal_scores = 1 - cal_smx[np.arange(size_cal_set), cal_labels]\n",
    "    alphas = []\n",
    "    prediction_sets = []\n",
    "    actual_labels = []\n",
    "    i = 0\n",
    "\n",
    "    for i, image in enumerate(val_smx):\n",
    "        # try alphas until there's only one class in the prediction set\n",
    "        for alpha in np.arange(0.01, 1, 0.0001):\n",
    "            q_level = np.ceil((size_cal_set + 1) * (1 - alpha)) / size_cal_set\n",
    "            qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "            prediction_set = image >= (1 - qhat)\n",
    "\n",
    "            if np.sum(prediction_set) == 1:\n",
    "                prediction_sets.append(prediction_set)\n",
    "                alphas.append(alpha)\n",
    "                actual_labels.append(val_labels[i])\n",
    "                break\n",
    "\n",
    "            elif alpha >= 0.999:\n",
    "                prediction_sets.append(prediction_set)\n",
    "                alphas.append(alpha)\n",
    "                actual_labels.append(val_labels[i])\n",
    "                break\n",
    "\n",
    "    return prediction_sets, alphas, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate empirical coverage of conformal prediction\n",
    "def evaluate_conformal(prediction_sets, actual_labels):\n",
    "    prediction_sets = np.array(prediction_sets)\n",
    "    actual_labels = np.array(actual_labels)\n",
    "    empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),actual_labels].mean()\n",
    "    print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "    return empirical_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_logits(alphas):\n",
    "    fake_logits = 1 - np.array(alphas)\n",
    "    return fake_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.9375593291846852\n"
     ]
    }
   ],
   "source": [
    "# test our functions\n",
    "data = datafile_to_df(\"../data-files/cifar10_probs.csv\")\n",
    "smx, labels = get_smx_and_labels(data)\n",
    "cal_smx, val_smx, cal_labels, val_labels = generate_cal_val_sets(smx, labels, 500)\n",
    "prediction_sets, alphas, actual_labels = conformal(cal_smx, cal_labels, val_labels, val_smx, 500)\n",
    "empirical_coverage = evaluate_conformal(prediction_sets, actual_labels)\n",
    "fake_logits = create_fake_logits(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99 , 0.99 , 0.978, ..., 0.99 , 0.98 , 0.99 ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.32159560e-09, 2.90598440e-08, 6.05252570e-12, ...,\n",
       "        2.43733570e-11, 1.00000000e+00, 6.95829800e-09],\n",
       "       [6.39322760e-07, 5.89543530e-08, 2.75454200e-06, ...,\n",
       "        9.70621600e-07, 3.20337360e-08, 3.29595660e-08],\n",
       "       [1.20873450e-06, 1.06236540e-04, 5.98267930e-06, ...,\n",
       "        6.13088900e-08, 1.97542830e-05, 2.48818740e-05],\n",
       "       ...,\n",
       "       [1.10834820e-04, 1.19870450e-05, 1.84343880e-03, ...,\n",
       "        6.89586800e-03, 2.81216460e-04, 9.82191300e-07],\n",
       "       [5.02782260e-10, 1.10962555e-08, 6.88817600e-10, ...,\n",
       "        2.96725700e-09, 3.79553940e-10, 3.04901400e-08],\n",
       "       [2.27233250e-09, 1.51230020e-09, 8.39111400e-08, ...,\n",
       "        1.15076500e-07, 1.00618200e-09, 2.20164620e-10]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_smx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_smx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
