{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1.9216972e-07, 0.002469865, 3.1885104e-12, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.20628296, 1.48559475e-05, 1.4134733e-06, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "      <td>[4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5</td>\n",
       "      <td>[8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7</td>\n",
       "      <td>[4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             output\n",
       "0         3  [2.3661317e-09, 1.266867e-08, 8.9752067e-10, 0...\n",
       "1         8  [2.0486328e-11, 8.667231e-08, 4.1953889e-16, 1...\n",
       "2         8  [1.9216972e-07, 0.002469865, 3.1885104e-12, 3....\n",
       "3         0  [0.999424, 1.3174234e-05, 4.9130163e-06, 2.804...\n",
       "4         6  [3.4858956e-09, 1.7338067e-06, 1.1511221e-06, ...\n",
       "...     ...                                                ...\n",
       "9995      8  [0.20628296, 1.48559475e-05, 1.4134733e-06, 2....\n",
       "9996      3  [4.3346837e-14, 1.0565218e-13, 8.082701e-10, 1...\n",
       "9997      5  [8.1107293e-10, 9.9917585e-09, 7.729877e-08, 1...\n",
       "9998      1  [1.5138195e-08, 0.99875677, 1.074252e-05, 3.15...\n",
       "9999      7  [4.629024e-09, 4.5464247e-08, 4.4147014e-10, 5...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell to run on cifar10_probs.csv (from resnet110)\n",
    "\n",
    "# make df where column \"label\" is column 10 of data_cifar10_probs and column \"output\" is an array of the first 10 columns of data_cifar10_probs as a list of floats\n",
    "data_cifar10_probs = pd.read_csv('notebooks/cifar10_probs.csv', sep=',', header=None)\n",
    "data_cifar10_probs = data_cifar10_probs.rename(columns={10: \"label\"})\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs.iloc[:, 0:10].values.tolist()\n",
    "# make \n",
    "\n",
    "data_cifar10_probs = data_cifar10_probs.drop(data_cifar10_probs.columns[0:10], axis=1)\n",
    "data_cifar10_probs[\"output\"] = data_cifar10_probs[\"output\"].astype(str)\n",
    "\n",
    "data_cifar10_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to run on labels_convolutional_cifar10.csv\n",
    "\n",
    "# # we have to remember to turn \" \" into \",\"\n",
    "# data1 = pd.read_csv('labels (2).csv', sep=';')\n",
    "# # get types of columns\n",
    "# type(data1[\"output\"][0])\n",
    "\n",
    "# we have to remember to turn \" \" into \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smx = data_cifar10_probs['output']\n",
    "labels = data_cifar10_probs['label'].astype(int)\n",
    "\n",
    "# create an empty array\n",
    "lista = np.array([])\n",
    "for i in range(len(smx)):\n",
    "    lista = np.append(lista, literal_eval(smx[i]))\n",
    "    \n",
    "smx = lista.reshape(len(smx), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.02 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "\n",
    "# n Trues e (smx.shape[0]-n) Falses\n",
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0 \n",
    "\n",
    "# embaralha os Trues e Falses\n",
    "np.random.shuffle(idx) \n",
    "\n",
    "# pega os valores de softmax de acordo com os Trues e Falses\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx, :] \n",
    "#val_smx = val_smx[2].reshape(1,10) #use to have 1 img to predict\n",
    "\n",
    "\n",
    "# pega os valores de labels de acordo com os Trues e Falses\n",
    "cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])\n",
    "#cal_labels, val_labels = np.array(labels[idx]), np.array(labels[~idx])[2] #use to have 1 img to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 10), (9500, 10))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_smx.shape, val_smx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), (9500,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_labels.shape, val_labels.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal prediction happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cal_scores = 1 - cal_smx[np.arange(n), cal_labels]\n",
    "alphas = []\n",
    "i =0 \n",
    "for image in val_smx:\n",
    "    \n",
    "    # try alphas until there's only one class in the prediction set\n",
    "    for alpha in np.arange(0.01, 1, 0.0001):\n",
    "        q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
    "        qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "        prediction_sets = [image] >= (1 - qhat)  # 3: form prediction sets\n",
    "\n",
    "        if np.sum(prediction_sets) == 1:\n",
    "            alphas.append(alpha)\n",
    "            break  # exit the inner loop if an alpha is foundz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9482"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99  0.99  0.978 ... 0.99  0.98  0.99 ]\n"
     ]
    }
   ],
   "source": [
    "# create fake logits list (1-alphas)\n",
    "fake_logits = 1 - np.array(alphas)\n",
    "print(fake_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "\n",
    "# criamos um vetor cal_scores com (1 -(probabilidade atribuida pelo modelo de que a imagem tenha seu label verdadeiro))\n",
    "# cal score é quanto menor, melhor\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "\n",
    "# 2: get adjusted quantile\n",
    "# qhat será o valor de s_i (entrada de cal_scores) que limita os 1-alpha menores scores (os melhores!)\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')\n",
    "\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empirical coverage is: 0.28378947368421054\n"
     ]
    }
   ],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 10)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6802\n"
     ]
    }
   ],
   "source": [
    "# prediction_sets_one_guess = prediction_set removing all lists with only one guess\n",
    "prediction_sets_many_guesses = []\n",
    "for i in range(len(prediction_sets)):\n",
    "    if prediction_sets[i].sum() != 1:\n",
    "        prediction_sets_many_guesses.append(prediction_sets[i])\n",
    "    else:\n",
    "        # make val_labels[i]==-1\n",
    "        val_labels[i] = -1\n",
    "\n",
    "# remove all -1 from val_labels\n",
    "val_labels = val_labels[val_labels != -1]\n",
    "\n",
    "# get the accuracy of the model\n",
    "accuracy = 0\n",
    "for i in range(len(prediction_sets_many_guesses)):\n",
    "    if prediction_sets_many_guesses[i][val_labels[i]] == True:\n",
    "        accuracy += 1\n",
    "print(accuracy)\n",
    "print(len(prediction_sets_many_guesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6802 is out of bounds for axis 0 with size 6802",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Carol Erthal\\Documents\\fgv\\5P\\ML\\conformal-prediction-evaluation\\conformalTesting.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         prediction_sets_one_guess\u001b[39m.\u001b[39mappend(prediction_sets[i])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# make val_labels[i]==-1\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         val_labels[i] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# remove all -1 from val_labels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/ML/conformal-prediction-evaluation/conformalTesting.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m val_labels \u001b[39m=\u001b[39m val_labels[val_labels \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6802 is out of bounds for axis 0 with size 6802"
     ]
    }
   ],
   "source": [
    "# prediction_sets_one_guess = prediction_set removing all lists with more than one guess\n",
    "prediction_sets_one_guess = []\n",
    "for i in range(len(prediction_sets)):\n",
    "    if prediction_sets[i].sum() == 1:\n",
    "        prediction_sets_one_guess.append(prediction_sets[i])\n",
    "    else:\n",
    "        # make val_labels[i]==-1\n",
    "        val_labels[i] = -1\n",
    "\n",
    "# remove all -1 from val_labels\n",
    "val_labels = val_labels[val_labels != -1]\n",
    "\n",
    "# get the accuracy of the model\n",
    "accuracy = 0\n",
    "for i in range(len(prediction_sets_one_guess)):\n",
    "    if prediction_sets_one_guess[i][val_labels[i]] == True:\n",
    "        accuracy += 1\n",
    "print(accuracy)\n",
    "print(len(prediction_sets_one_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times there is more than one label in the prediction set is: 0\n"
     ]
    }
   ],
   "source": [
    "# count how many times there is more than one label in the prediction set\n",
    "count = 0\n",
    "for i in range(len(prediction_sets)):\n",
    "    if sum(prediction_sets[i]) > 9:\n",
    "        count += 1\n",
    "print(f\"The number of times there is more than one label in the prediction set is: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
